{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation for training XLSR ASR models\n",
    "\n",
    "This notebook creates JSON files so that datasets can be read by Huggingface Datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/workspace/data/mal') # The path where you have downloaded and extracted datasets\n",
    "output_dir = Path('/workspace/data/mal/hf-dataset') # The output directory for new HF Datasets\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Set dataset folders under data_dir\n",
    "dataset_folders = {\n",
    "    'iiit': 'iiit_mal_abi',\n",
    "    'openslr': 'openslr',\n",
    "    'indic-tts': 'indic-tts-ml',\n",
    "    'msc-reviewed': 'msc-reviewed-speech-v1.0+20200825',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IIIT MAL Dataset\n",
    "The dataset was downloaded from [here](http://speech.iiit.ac.in/index.php/research-svl/69.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def output_dataset(dataset, output_path):\n",
    "    \"\"\"\n",
    "    Function to output given dataset to a directory\n",
    "    Each sample is written as JSON file\n",
    "    \"\"\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for i, sample in enumerate(dataset):\n",
    "        sample_dict = {\"path\": sample[0], \"sentence\":sample[1]}\n",
    "        with open(output_path/f'sample_{i}.json', 'w') as outfile:\n",
    "            json.dump(sample_dict, outfile)\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iiit_mal_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Generator to read IIIT dataset\n",
    "    \"\"\"\n",
    "    text_file = dataset_path / 'etc' / 'txt.done.data.utf8'\n",
    "    wav_dir = dataset_path / 'wav'\n",
    "    \n",
    "    with open(text_file, encoding='utf-8') as data_file:\n",
    "        for line in data_file:\n",
    "            cleaned_line = line[2:-4]\n",
    "            file_id = cleaned_line[:8]\n",
    "            text = cleaned_line[11:]\n",
    "            wav_path = wav_dir / f\"{file_id}.wav\" \n",
    "            wav_path_str = str(wav_path.absolute())\n",
    "            if wav_path.exists():\n",
    "                yield (wav_path_str, text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dataset generator and write it\n",
    "dataset = get_iiit_mal_dataset(data_dir/dataset_folders['iiit'])\n",
    "output_dataset(dataset, output_dir/dataset_folders['iiit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Openslr\n",
    "\n",
    "The dataset was downloaded from [here](http://openslr.org/63/). Put the TSV files and extracted dataset files into a directory. It should have following directories/files :\n",
    "```\n",
    "- line_index_female.tsv\n",
    "- line_index_male.tsv\n",
    "- ml_in_female (directory)\n",
    "- ml_in_male (directory)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openslr_dataset(dataset_path, subset_type):\n",
    "    \"\"\"Get generator for OPENSLR dataset\"\"\"\n",
    "    meta_file = dataset_path / f\"line_index_{subset_type}.tsv\"\n",
    "    wav_dir = dataset_path / f\"ml_in_{subset_type}\"\n",
    "    with open(meta_file, encoding='utf-8') as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            text = row[1]\n",
    "            file_id = row[0]\n",
    "            wav_path = wav_dir / f\"{file_id}.wav\"\n",
    "            wav_path_str = str(wav_path.absolute())\n",
    "            if wav_path.exists():\n",
    "                yield (wav_path_str, text)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2103\n",
      "2023\n"
     ]
    }
   ],
   "source": [
    "# Set dataset splits\n",
    "types = ['female', 'male']\n",
    "# Create HF datasets\n",
    "for subset_type in types:\n",
    "    dataset = get_openslr_dataset(data_dir/dataset_folders['openslr'], subset_type)\n",
    "    count = output_dataset(dataset, output_dir/dataset_folders['openslr'] / subset_type)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indic TTS\n",
    "\n",
    "The dataset was downloaded from [here](https://www.kaggle.com/kavyamanohar/indic-tts-malayalam-speech-corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indic_tts_dataset(dataset_path, subset_type):\n",
    "    \"\"\"Generator to get INDIC TTS dataset\"\"\"\n",
    "    subset_folder = dataset_path / f\"mono_{subset_type}_1\" / f\"mono_{subset_type}\"\n",
    "    meta_file = subset_folder / \"txt.done.data_original\"\n",
    "    if not meta_file.exists():\n",
    "        meta_file = subset_folder / \"txt.done.data\"\n",
    "    wav_dir = subset_folder / 'wav'\n",
    "    with open(meta_file, encoding='utf-8') as data_file:\n",
    "        for line in data_file:\n",
    "            cleaned_line = line[1:-4]\n",
    "            file_id = cleaned_line[:15]\n",
    "            text = cleaned_line[17:]\n",
    "            wav_path = wav_dir / f\"{file_id}.wav\" \n",
    "            wav_path_str = str(wav_path.absolute())\n",
    "            if wav_path.exists():\n",
    "                yield (wav_path_str, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950\n",
      "5649\n"
     ]
    }
   ],
   "source": [
    "# Set dataset splits\n",
    "types = ['female', 'male']\n",
    "# Create HF datasets\n",
    "for subset_type in types:\n",
    "    dataset = get_indic_tts_dataset(data_dir/dataset_folders['indic-tts'], subset_type)\n",
    "    count = output_dataset(dataset, output_dir/dataset_folders['indic-tts'] / subset_type)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSC Reviewed\n",
    "\n",
    "The dataset from SMC was downloaded from [here](https://blog.smc.org.in/malayalam-speech-corpus/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msc_reviewed_dataset(dataset_path):\n",
    "    \"\"\"Get generator for MSC reviewed\"\"\"\n",
    "    meta_file = dataset_path / 'metadata.tsv'\n",
    "    with open(meta_file) as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter='\\t')\n",
    "        headers = next(reader)\n",
    "        print(headers)\n",
    "        for row in reader:\n",
    "            wav_path = dataset_path / row[1]\n",
    "            wav_path_str = str(wav_path.absolute())\n",
    "            text = row[4]\n",
    "            if wav_path.exists():\n",
    "                yield (wav_path_str, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['speechid', 'speechpath', 'speaker_id', 'review_score', 'transcript', 'category', 'speaker_gender', 'speaker_age']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1541"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create HF Datasets\n",
    "dataset = get_msc_reviewed_dataset(data_dir/dataset_folders['msc-reviewed'])\n",
    "output_dataset(dataset, output_dir/dataset_folders['msc-reviewed'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
